---
layout: post
title: "Day 33 – From Graphs to Algorithms: Breathing Life into Air Quality Data"
date: 2025-07-10
author: Fikewa Akindolire
permalink: /day33.html
tags: ["Python" , "MSU Writing Center" , "Interpolation" , "30 Minute Data" , "John Hopkins" , "Deep Learning" , "Neural Networks"]

what_i_learned: |
    Today, we kicked off with a cohort-wide session in Morgan State’s business auditorium where we received an insightful lecture from the university’s Writing Center. Since we’re all currently drafting our final research papers, the session focused on how to effectively organize our thoughts, build strong arguments, and get the ball rolling on a high-quality academic report. It was a helpful reminder that technical work needs strong communication to have an impact.

    After lunch, I returned to my lab station and shifted gears to work on visualizing our dataset. I created eight separate graphs — four showing the relationship between AOD and time, and four showing PM2.5 and time — one pair for each year from 2019 to 2022. This allowed me to better understand the yearly trends in aerosol optical depth and particulate pollution.

    I then dove into interpolating the 1-hour data from the Padonia station to produce 30-minute intervals using a linear interpolation method. The output was exciting — smoother time resolution with accurate trend retention. I followed up by visualizing the interpolated data using both scatter plots and line graphs, which helped confirm the interpolation was successful.
    
    To deepen the analysis, I applied two machine learning algorithms — linear regression and decision tree regression — to model and better understand the behavior of PM2.5 across time. These methods offered a predictive layer to the dataset and helped set the foundation for more advanced analytics later.

blockers: |
    I had a bit of trouble with the line of code when I tried interpolating the 1 hour air quality data of Padonia. 
  
reflection: |
    Today felt like a great balance between structure and creativity. The Writing Center session was a grounding reminder of how essential it is to tell a clear and compelling story — especially when working with technical content. It gave me a fresh lens to approach the writing side of my final paper.

    On the technical side, I was proud to see how much my data skills have evolved. Interpolating time-series data and applying regression models used to feel intimidating, but today it felt like second nature. Creating those eight time-series graphs gave me a more intuitive understanding of air quality trends year over year. It’s rewarding to see both the code and the visuals come together to support real insights.

    As I continue, I’m excited to build on this momentum — maybe even experiment with more AI models or incorporate additional satellite stations. Today reaffirmed that each layer of analysis adds depth to the research, and that’s what makes this work meaningful.
  
---
